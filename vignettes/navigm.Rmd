---
title: Node-level auxiliary variables for improved graphical model inference (navigm)
author: Xiaoyue Xi, Sylvia Richardson, Helene Ruffieux
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Node-level auxiliary variables for improved graphical model inference (navigm)}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


<center>
## Abstract 
</center>

``navigm`` is a R package for incorporating node-level auxiliary variables in the Gaussian graphical models. In contrast with standard Gaussian graphical models, it features the option to include and select node-leve variables contributing to node centrality. This package provides not only the previously proposed expectation-maximisation algorithm for graphical spike-and-slab inference, but it also implements a new variational Bayes expectation-maximisation algorithm to approximate the posterior distribution. 



# Introduction
First, load the package using the command
```{r setup, eval = F, include = T}
library(navigm)
```

```{r personal install, eval=T, include = F}
devtools::load_all('~/navigm/')
```

The main function ``navigm`` takes a data matrix *$Y$* of dimension $N \times P$, where $N$ is the sample size, and $P$ is the number of nodes in the graph. It allows for an additional input matrix *$V$* of dimension $P \times Q$, which comprises node-level auxiliary variables that may influence node degrees and graph structure, where $Q$ is the number of auxiliary variables. In this vignette, assume $N=100$, $P=20$, and $Q=10$, and one of the $Q$ variables affects the degree of nodes.

## Data simulation
We generate the node-level variable matrix *$V$* from a right-skewed beta distribution. Suppose most auxiliary variables do not affect graph structure, and only one variable is "active", of which the effect size is generated from a log-normal distribution centered at 0.5, defining **$\beta$**.
Both quantities give rise to the hub propensities **$V\beta$**. 
Set $\zeta=-1.2$, and the probability of including the edge $(i,j)$ is given by $$ \Phi (\zeta + \sum V_{iq} \beta_q + \sum V_{jq} \beta_q), $$ where $\Phi$ denotes the normal cumulative density function. If the probability is $\geq 0.5$, the edge $(i,j)$ exist; otherwise, it does not, which defines the adjacency matrix. $N = 100$ samples are then generated from a multivariate normal distribution with mean **0** and the precision matrix following the adjacency structure.

```{r generate_ss, eval = T, include = T}
set.seed(123)

#
N <- 100
P <- 20
Q <- 10
Q0 <- 1

#
V <- generate_V(P, Q)

#
beta0 <- 0.5
sig2_beta0 <- 0.1
beta_true <- rlnorm(Q0, log(beta0), sig2_beta0)
beta_true_gmss <- rep(0, Q)
beta_true_gmss[sample(1:Q, Q0)] <- beta_true

#
theta <- V %*% matrix(beta_true_gmss, ncol = 1)
zeta <-  - 1.2
pe <- matrix(theta, nrow = P, ncol = P)
pe <- pe + t(pe) + zeta
pe <- pnorm(pe)
A <- 0 + (pe >= 0.5)
diag(A) <- 0

#
net <-  generate_data_from_adjancency(N = N, A = A)
```

The sparsity of the simulated adjacency matrix is `r round(sum(net$A[upper.tri(net$A)])/sum(upper.tri(net$A)),4) * 100`%.
The simulated data matrix and node-level variable matrix are shown below, where the y-axes represent node-level variables. The x-axis in the left panel represents samples, and the x-axis in the right panel represents auxiliary variables.

```{r plotY_ss, eval = T, include = T, echo=F}
library(ggplot2)
rY <- reshape::melt(net$Y) 
g1 <- ggplot(rY, aes(X1, X2)) +                         
  geom_tile(aes(fill = value)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  scale_fill_gradient2(low="navy", mid="white", high="red", 
                       midpoint=0)+
  labs(x = '', y = '', fill='') + 
  theme(legend.position = 'none',
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())+
  guides(fill = guide_colourbar(barwidth = 0.5))+
  theme_classic()

rV <- reshape::melt(V) 
g2 <- ggplot(rV, aes(X2, X1)) +                         
  geom_tile(aes(fill = value)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  scale_fill_gradient2(low="navy", mid="white", high="red", 
                       midpoint=0)+
  labs(x = '', y = '', fill='') + 
  theme(legend.position = 'none',
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())+
  guides(fill = guide_colourbar(barwidth = 0.5))+
  theme_classic()
g1; g2
```


The package provides two choices of inference algorithms to estimate the graph structure and identify "active" node-level variables based on the two input matrices.

### Inference using expectation maximization

We then input the simulated data ``net$Y`` and ``V`` into ``navigm`` to infer the precision matrix using spike-and-slab Gaussian graphical models with spike-and-slab priors on auxiliary variable coefficients, employing the expectation-maximization (EM) algorithm.
```{r gmssem, eval = T, include = T}
gmss_em <- navigm(Y = net$Y, V = V, method = 'GMSS', inference = 'EM', numCore = 2)
```
Note that ``numCore = 2``  is restricted in this vignette due to an issue mentioned in [the link](https://stackoverflow.com/questions/41307178/error-processing-vignette-failed-with-diagnostics-4-simultaneous-processes-spa). In practice, users may set this to NULL, which will automatically detect the number of cores available on their devices.

### Inference using variational Bayes expectation maximization

To use the variational expectation maximization (VBEM) algorithm, we implement the following command:
```{r gmssvbem, eval = T, include = T}
gmss_vbem <- navigm(Y = net$Y, V = V, method = 'GMSS', numCore = 2)
```


This shows less computational time for the VBEM algorithm since the double grid search in two-level continuous spike-and-slabs is not needed, unlike in the EM algorithm. Additionally, the EM algorithm returns a warning when selecting the model with the smallest edge-level spike variances on the grid. This warning suggests we cannot exclude the case that smaller spike variances may be more suitable, and the selected model may not be optimal.

# Data visualisation 
The package provides visualizations for both simulated data and model estimates. For instance, we visualize simulated data and the inference output from the VBEM algorithm:

* Plot the simulated graph and the graph estimate. 

```{r plotnet_gmssvbem,out.width='.7\\linewidth', fig.width=6, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2), mar = c(0,1,0,1))
plot_network(net$A, node_names = 1:P)
plot_network(gmss_vbem$estimates$m_delta >= 0.5, node_names = 1:P)
```

It shows the edges in the network are well recovered. 

* Plot the simulated regression coefficients and estimated posterior inclusion probabilities of auxiliary variables.

```{r plotppi_gmssvbem,out.width='.7\\linewidth', fig.width=8, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2))
plot_ppi(beta_true_gmss, condition = (beta_true_gmss!=0))
plot_ppi(gmss_vbem$estimates$m_gamma, ylab = "PIP")
```

In the left panel, one auxiliary variable is simulated as "active". Although all the posterior inclusion probabilities are low in the right panel, the variable simulated as "active" has higher probabilities than others.

* Plot the truncated ROC curves (a threshold-free accuracy measure).

```{r plotrroc_gmssvbem,out.width='.7\\linewidth', fig.width=8, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2))

plot_roc(gmss_em$estimates$P1[upper.tri(net$A)], net$A[upper.tri(net$A)],col = 'black',fpr_stop = 0.1, main = 'edge selection')
plot_roc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)],col = 'red',fpr_stop = 0.1,add = T)
  legend("bottomright", legend = c("EM","VBEM"),
           lty = 1, cex = 0.7, col = c('black','red'))
  
plot_roc(gmss_em$estimates$P2, beta_true_gmss!=0, col = 'black',fpr_stop = 0.1,main = 'variable selection')
plot_roc(gmss_vbem$estimates$m_gamma, beta_true_gmss!=0,col = 'red',fpr_stop = 0.1, add = T)
  legend("bottomright", legend = c("EM","VBEM"),
           lty = 1, cex = 0.7, col = c('black','red'))
  
```

This shows superior performance of the VBEM in edge selection, and similar performance in node-level variable selection in this example. The very poor edge selection for the EM might be attributed to the boundary spike variance selected.

* Alternatively, the standardized area under the truncated ROC curve can be evaluated, for example, by  ``compute_pauc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)], fpr_stop = 0.1, standardise = T)`` and this gives `r compute_pauc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)], fpr_stop = 0.1, standardise = T)`.

* Calculate threshold-based accuracy measures for

  + the edge selection:
```{r accuracy_gmssvbem_edge}
print(compute_perf(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)]))
```

  + the node-level variable selection:
```{r accuracy_gmssvbem}
print(compute_perf(gmss_vbem$estimates$m_gamma, beta_true_gmss!=0))
```
  
These two outputs are subject to the threshold choices. The threshold is specified to 0.5 in this example. Alternatively, a [false discovery rate derived threshold](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-14/issue-2/A-global-local-approach-for-detecting-hotspots-in-multiple-response/10.1214/20-AOAS1332.full) may be employed.   

# Simpler models
The package allows for the following simpler models:

* A model without node-level variable selection is available by setting ``method = 'GMN'``. This is useful when a low number of node-level auxiliary variables are included.
* A standard graphical spike-and-slab model can be set by using ``method = 'GM' ``. Its inference through the EM algorithm is the same as [EMGS](https://www.tandfonline.com/doi/full/10.1080/10618600.2019.1609976) except we allow learning the scales of continuous spike-and-slab variances.

## Graphical spike-and-slab with normal priors on auxiliary variable coefficients
Suppose we have a small number of node-level auxiliary variables, and variable selection is not required. The data are simulated following the previous procedure.

```{r generate_n, eval = T, include = T}
set.seed(123)

#
N <- 100
P <- 20
Q <- Q0 <- 3

#
V <- generate_V(P, Q)

#
beta0 <- 0.5
sig2_beta0 <- 0.1
beta_true <- rlnorm(Q0, log(beta0), sig2_beta0)
beta_true_gmn <- rep(0, Q)
beta_true_gmn[sample(1:Q, Q0)] <- beta_true

#
theta <- V %*% matrix(beta_true_gmn, ncol = 1)
zeta <-  - 1.2
pe <- matrix(theta, nrow = P, ncol = P)
pe <- pe + t(pe) + zeta
pe <- pnorm(pe)
A <- 0 + (pe >= 0.5)
diag(A) <- 0

#
net <-  generate_data_from_adjancency(N = N, A = A)
```

The sparsity of the simulated adjacency matrix is `r round(sum(net$A[upper.tri(net$A)])/sum(upper.tri(net$A)),4) * 100`%.

#### Inference using expectation maximization

We then input the simulated data ``net$Y``and ``V`` into ``navigm`` and infer the precision matrix using spike-and-slab Gaussian graphical models with normal priors on auxiliary variable coefficients using the EM algorithm.

```{r gmnem, eval = T, include = T}
gmn_em <- navigm(Y = net$Y, V = V, method = 'GMN', inference = 'EM', numCore = 2)
```


#### Inference using variational Bayes expectation maximization
To use the variational expectation maximization, we implement the command as follows.

```{r gmnvbem, eval = T, include = T}
gmn_vbem <- navigm(Y = net$Y, V = V, method = 'GMN', numCore = 2)
```


## Standard graphical spike-and-slab without external node-level data
Finally, we only use the primary data of interests, ``net$Y``, for the graphical spike-and-slab, as is done in most studies using Gaussian graphical models.

### Inference using expectation maximization
We first make the inference of the graphical spike-and-slab using the EM algorithm.
```{r gmem, eval = T, include = T}
gm_em <- navigm(Y = net$Y, method = 'GM', inference = 'EM', version = 1, numCore = 2)
```


### Inference using variational Bayes expectation maximization
The following command uses the VBEM algorithm for the inference.
```{r gmvbem, eval = T, include = T}
gm_vbem <- navigm(Y = net$Y, method = 'GM', version = 1, numCore = 2)
```

Note that ``version = 1 `` uses the beta prior on edge inclusion probability as in [EMGS](https://www.tandfonline.com/doi/full/10.1080/10618600.2019.1609976).
``version = 2`` uses the normal prior on probit-transformed edge inclusion probability to 
keep it comparable with our model extensions. 
