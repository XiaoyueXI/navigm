---
title: Node-level auxiliary variables for improved graphical model inference (navigm)
author: Xiaoyue Xi, Sylvia Richardson, Helene Ruffieux
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Node-level auxiliary variables for improved graphical model inference (navigm)}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


<center>
## Abstract 
</center>

``navigm`` is a R package for incorporating node-level auxiliary variables in the Gaussian graphical models. In contrast with standard Gaussian graphical models, it features the option to include and select node-leve variables contributing to node centrality. This package provides the previously proposed expectation-maximisation algorithm for graphical spike-and-slab inference, and it implements a variational Bayes expectation-maximisation algorithm to approximate the posterior distribution. 



# Introduction
First, load the package by the command. 
```{r setup, eval = F, include = T}
library(navigm)
```

```{r personal install, eval=T, include = F}
devtools::load_all('~/navigm/')
```

The main function ``navigm`` takes a data matrix $Y$ of dimension N x P, where N is the sample size and P is the number of nodes in the graph. It allows for an addition input matrix $V$ of dimension P x Q, which comprises node-level auxiliary variables and may influence node degrees and graph structure, where Q is the number of auxiliary variables. In this vignette, assume $N=100$, $P=20$ and $Q=10$, and one of Q variables affect the degree of nodes.

## Data simulation
We generate the node-level variable matrix $V$ from a right-skewed beta distribution. Suppose most auxiliary variable does not affact graph structure, and only one variable is "active" of which the effect size is generated from log-normal distribution centered at 0.5, which defines **$\beta$**.
Both quantities give rise to the hub propensities **$V\beta$**. 
Set $\zeta=-1.5$, and the probability of including the edge $(i,j)$ is $$ \Phi (\zeta + \sum V_{iq} \beta_q + \sum V_{jq} \beta_q). $$ 
If the probability is $\geq 0.5$, the edge $(i,j)$ exist; otherwise not, which defines the adjancency matrix.
$N = 100$ samples are then generated from a multivariate normal distribution with mean **0** and the precision matrix following the adjancency structure.

```{r generate_ss, eval = T, include = T}

set.seed(123)

#
N <- 100
P <- 20
Q <- 10
Q0 <- 1

#
V <- generate_V(P, Q, alpha = 0.05, beta = 0.2, Sigma = diag(Q), min_gene = 1)

#
beta0 <- 0.5
sig2_beta0 <- 0.1
beta_true <- rlnorm(Q0, log(beta0), sig2_beta0)
beta_true_gmss <- rep(0, Q)
beta_true_gmss[sample(1:Q, Q0)] <- beta_true

#
theta <- V %*% matrix(beta_true_gmss, ncol = 1)
zeta <-  - 1.2
pe <- matrix(theta, nrow = P, ncol = P)
pe <- pe + t(pe) + zeta
pe <- pnorm(pe)
A <- 0 + (pe >= 0.5)
diag(A) <- 0

#
net <-  generate_data_from_adjancency(N = N, A = A)
```

The data matrix and node-level variable matrix are shown as follows, where the y-axes represent node-level variables. 

```{r plotY_ss, eval = T, include = T, echo=F}
library(ggplot2)
rY <- reshape::melt(net$Y) 
g1 <- ggplot(rY, aes(X1, X2)) +                         
  geom_tile(aes(fill = value)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  scale_fill_gradient2(low="navy", mid="white", high="red", 
                       midpoint=0)+
  labs(x = '', y = '', fill='') + 
  theme(legend.position = 'none',
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())+
  # guides(fill = guide_colourbar(barwidth = 0.5))+
  theme_classic()

rV <- reshape::melt(V) 
g2 <- ggplot(rV, aes(X2, X1)) +                         
  geom_tile(aes(fill = value)) + 
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) + 
  scale_fill_gradient2(low="navy", mid="white", high="red", 
                       midpoint=0)+
  labs(x = '', y = '', fill='') + 
  theme(legend.position = 'none',
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())+
  # guides(fill = guide_colourbar(barwidth = 0.5))+
  theme_classic()
g1; g2
```


The package provide two choices of inference algorithm for estimate graph structure and "active" node-level variables based on the two input matrices.

### Inference using expectation maximization

We then input the simulated data ``net$Y``and ``V`` into the ``navigm`` and infer the precision matrix by spike-and-slab Gaussian graphical models with spike-and-slab priors on auxiliary variable coefficients using the expectation maximization (EM) algorithm. 
```{r gmssem, eval = T, include = T}
gmss_em <- navigm(Y = net$Y, V = V, method = 'GMSS', inference = 'EM', numCore = 2)
```
Note ``numCore = 2`` is restricted due to an issue in [vignette](https://stackoverflow.com/questions/41307178/error-processing-vignette-failed-with-diagnostics-4-simultaneous-processes-spa). Users may set this to ``NULL`` which automatically detects the number of cores in their devices in practice. 

### Inference using variational Bayes expectation maximization

To use the variational expectation maximization (VBEM) algorithm, we implement the command
```{r gmssvbem, eval = T, include = T}
gmss_vbem <- navigm(Y = net$Y, V = V, method = 'GMSS', numCore = 2)
```


This shows less computational time for the VBEM algorithm, as the double grid search in two-level continuous spike-and-slabs is not needed in the VBEM algorithm as in the EM. Also the EM algorithm returns a warning on selecing the model with the smallest edge-level spike variances on the grid. We cannot exclude the case that smaller spike variances may be more suited, and the selected model may not be optimal.

# Data visualisation 
The package provides visualizations to both simulated data and model estimates. For instance, we visualize simulated data and the inference output from the VBEM:

- plot the simulated graph and the graph estimate. 

```{r plotnet_gmssvbem,out.width='.7\\linewidth', fig.width=6, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2), mar = c(0,1,0,1))
print(plot_network(net$A, node_names = 1:P))
print(plot_network(gmss_vbem$estimates$m_delta >= 0.5, node_names = 1:P))
```

- plot the simulated regression coefficients and estimated posterior inclusion probabilities of auxiliary variables.

```{r plotppi_gmssvbem,out.width='.7\\linewidth', fig.width=8, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2))
plot_ppi(beta_true_gmss, condition = (beta_true_gmss!=0))
plot_ppi(gmss_vbem$estimates$m_gamma, ylab = "PIP")
```

- plot the truncated ROC curves (a threshold-free accuracy measure)

```{r plotrroc_gmssvbem,out.width='.7\\linewidth', fig.width=8, fig.height=3,fig.show='hold',fig.align='center'}
par(mfrow = c(1,2))

plot_roc(gmss_em$estimates$P1[upper.tri(net$A)], net$A[upper.tri(net$A)],col = 'black',fpr_stop = 0.1, main = 'edge selection')
plot_roc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)],col = 'red',fpr_stop = 0.1,add = T)
  legend("bottomright", legend = c("EM","VBEM"),
           lty = 1, cex = 0.7, col = c('black','red'))
  
plot_roc(gmss_em$estimates$P2, beta_true_gmss!=0, col = 'black',fpr_stop = 0.1,main = 'variable selection')
plot_roc(gmss_vbem$estimates$m_gamma, beta_true_gmss!=0,col = 'red',fpr_stop = 0.1, add = T)
  legend("bottomright", legend = c("EM","VBEM"),
           lty = 1, cex = 0.7, col = c('black','red'))
  
```

This shows superior performance of the VBEM in edge selection, and similar performance in node-level variable selection in this example. The very poor edge selection for the EM might be attributed to the boundary spike variance selected. Alternatively, the standardized area under the truncated ROC curve can be evaluated, for example, by ``compute_pauc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)], fpr_stop = 0.1)`` and this gives `r compute_pauc(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)], fpr_stop = 0.1)`.

- calculate threshold-based accuracy measures

Edge selection:
```{r accuracy_gmssvbem_edge}
print(compute_perf(gmss_vbem$estimates$m_delta[upper.tri(net$A)], net$A[upper.tri(net$A)]))
```

Node-level variable selection:
```{r accuracy_gmssvbem}
print(compute_perf(gmss_vbem$estimates$m_gamma, beta_true_gmss!=0))
```
  
# Simpler models
The package allows for the simpler models:
- A model without node-level variable selection is available by setting ``method = 'GMN'``. This is useful when a low number of node-level auxiliary variables are included.
- A standard graphical spike-and-slab by setting ``method = 'GM' ``. Its inference through the EM algorithm is the same as [EMGS](https://www.tandfonline.com/doi/full/10.1080/10618600.2019.1609976) except we allow learning the scales of continuous spike-and-slab variances.

## Graphical spike-and-slab with normal priors on auxiliary variable coefficients
Suppose we have a small number of node-level auxiliary variables and variable selection is not required.

```{r generate_n, eval = T, include = T}

set.seed(123)

#
N <- 100
P <- 20
Q <- Q0 <- 3

#
V <- generate_V(P, Q, alpha = 0.05, beta = 0.2, Sigma = diag(Q), min_gene = 1)

#
beta0 <- 0.5
sig2_beta0 <- 0.1
beta_true <- rlnorm(Q0, log(beta0), sig2_beta0)
beta_true_gmn <- rep(0, Q)
beta_true_gmn[sample(1:Q, Q0)] <- beta_true

#
theta <- V %*% matrix(beta_true_gmn, ncol = 1)
zeta <-  - 1.5
pe <- matrix(theta, nrow = P, ncol = P)
pe <- pe + t(pe) + zeta
pe <- pnorm(pe)
A <- 0 + (pe >= 0.5)
diag(A) <- 0

#
net <-  generate_data_from_adjancency(N = N, A = A)


```

#### Inference using expectation maximization

We then input the simulated data ``net$Y``and ``Vn`` into the ``navigm`` and infer the precision matrix by spike-and-slab Gaussian graphical models with normal priors on auxiliary variable coefficients using the EM algorithm.
```{r gmnem, eval = T, include = T}
gmn_em <- navigm(Y = net$Y, V = V, method = 'GMN', inference = 'EM', numCore = 2)
```


#### Inference using variational Bayes expectation maximization
To use the variational expectation maximization, we implement the command as follows.
```{r gmnvbem, eval = T, include = T}
gmn_vbem <- navigm(Y = net$Y, V = V, method = 'GMN', numCore = 2)
```


## Standard graphical spike-and-slab without external data
Finally, we only use the primary data of interests ``net$Y`` to the graphical spike-and-slab as most studies in Gaussian graphical models.

### Inference using expectation maximization
We fist make the inference of the graphical spike-and-slab using the EM algorithm.
```{r gmem, eval = T, include = T}
gm_em <- navigm(Y = net$Y, method = 'GM', inference = 'EM', version = 1, numCore = 2)
```


### Inference using variational Bayes expectation maximization
The following command uses the VBEM algorithm for the inference.
```{r gmvbem, eval = T, include = T}
gm_vbem <- navigm(Y = net$Y, method = 'GM', version = 1, numCore = 2)
```

``version = 1 `` uses the same beta prior on edge inclusion probability as [EMGS](https://www.tandfonline.com/doi/full/10.1080/10618600.2019.1609976).
``version = 2`` uses the normal prior on probit-transformed edge inclusion probability to 
keep comparable with our model extension. 
